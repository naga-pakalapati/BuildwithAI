{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preliminary_data_checks_Hackathon2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ruul2WGlnK7s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b10dbc7-42aa-46be-9366-78f337c12556"
      },
      "source": [
        "!pip install pyspellchecker\n",
        "!pip install sentence-transformers\n",
        "!pip install pprint\n",
        "!pip install scipy\n",
        "!pip install afinn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/d1/ec4e830e9f9c1fd788e1459dd09279fdf807bc7a475579fd7192450b879c/pyspellchecker-0.5.4-py2.py3-none-any.whl (1.9MB)\n",
            "\r\u001b[K     |▏                               | 10kB 20.1MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 6.1MB/s eta 0:00:01\r\u001b[K     |▌                               | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |█                               | 61kB 7.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 71kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▍                              | 81kB 7.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 92kB 7.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |██                              | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▋                             | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |███                             | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |███                             | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |████                            | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 573kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 583kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 593kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 604kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 614kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 624kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 634kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 645kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 655kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 665kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 675kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 686kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 696kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 706kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 716kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 727kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 737kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 747kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 757kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 768kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 778kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 788kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 798kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 808kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 819kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 829kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 839kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 849kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 860kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 870kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 880kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 890kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 901kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 911kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 921kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 931kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 942kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 952kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 962kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 972kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 983kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 993kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.0MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.6MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.7MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.8MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.9MB 8.1MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.5.4\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/e0/65ad8fd86eba720412d9ff102c4a3540a113bbc6cd29b01e7ecc33ebb1fa/sentence-transformers-0.3.2.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hCollecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 22.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.2-cp36-none-any.whl size=93964 sha256=3cabd4b1d2f3c2666db2d33a6405ddf189f3df030257e1a8bd1d037ef5ffae98\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/06/a0/567f3651876165429f6510d3197b011652a25e547552816824\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=b9e961857afcde07c3bf35f8d3ba41eff112f7ecc0acd270d4c040a5c98ba458\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.2 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Collecting pprint\n",
            "  Downloading https://files.pythonhosted.org/packages/99/12/b6383259ef85c2b942ab9135f322c0dce83fdca8600d87122d2b0181451f/pprint-0.1.tar.gz\n",
            "Building wheels for collected packages: pprint\n",
            "  Building wheel for pprint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pprint: filename=pprint-0.1-cp36-none-any.whl size=1251 sha256=e30f971ff4da4774d56d806cf4560e471450171d0d24d7fcd0cc49b589e39fb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/d4/c6/16a6495aecc1bda5d5857bd036efd50617789ba9bea4a05124\n",
            "Successfully built pprint\n",
            "Installing collected packages: pprint\n",
            "Successfully installed pprint-0.1\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Collecting afinn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/e5/ffbb7ee3cca21ac6d310ac01944fb163c20030b45bda25421d725d8a859a/afinn-0.1.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: afinn\n",
            "  Building wheel for afinn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for afinn: filename=afinn-0.1-cp36-none-any.whl size=53452 sha256=e6df588a41d000ce99936579fb3adfa65b15952779ce85f8a74f31e26d786d4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/1c/de/428301f3333ca509dcf20ff358690eb23a1388fbcbbde008b2\n",
            "Successfully built afinn\n",
            "Installing collected packages: afinn\n",
            "Successfully installed afinn-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzgSXDVwnNU5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "a7b7cd6b-5bc7-433c-8790-ad032c6e7f3a"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import string\n",
        "from spellchecker import SpellChecker\n",
        "import nltk\n",
        "nltk.download('stopwords')#Error loading\n",
        "nltk.download('punkt')#Error loading\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import word_tokenize, pos_tag\n",
        "from nltk.stem import SnowballStemmer\n",
        "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
        "import cufflinks as cf\n",
        "cf.go_offline()\n",
        "cf.set_config_file(offline=False, world_readable=True)\n",
        "\n",
        "import pickle\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "import scipy as scipy\n",
        "\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import en_core_web_sm\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SugdCZKTnRqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/content/drive/My Drive/Hackathon_2020/data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8Aqs-YwnU1N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "8761aca0-d336-40d7-815a-f593cf408da0"
      },
      "source": [
        "df_geotagged = pd.read_csv(os.path.join(path, 'all_tweets_usa.csv'),\n",
        "                           header = 0, sep = ',', error_bad_lines=False, encoding = \"ISO-8859-1\", parse_dates = True)\n",
        "df_geotagged = df_geotagged.drop(['Unnamed: 0'], axis = 1)\n",
        "df_geotagged.drop_duplicates(inplace=True)\n",
        "df_geotagged = df_geotagged[df_geotagged['text'].notna()]\n",
        "df_geotagged['is_retweet'] = df_geotagged['text'].apply(lambda x: x[:2]=='RT')\n",
        "print(\"Total number of Retweets: {}\".format(df_geotagged['is_retweet'].sum()))\n",
        "df_geotagged"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6b00d3e31245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_geotagged = pd.read_csv(os.path.join(path, 'all_tweets_usa.csv'),\n\u001b[0;32m----> 2\u001b[0;31m                            header = 0, sep = ',', error_bad_lines=False, encoding = \"ISO-8859-1\", parse_dates = True)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_geotagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_geotagged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_geotagged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_geotagged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_geotagged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_geotagged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1872\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Hackathon_2020/data/all_tweets_usa.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69qewpU99GdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "aba3a796-c1b4-4a39-add1-8a2d6763126f"
      },
      "source": [
        "df_geotagged.columns\n",
        "df_geotagged['user_screen_name'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VirallyAds         2170\n",
              "pairsonnalitesN    1764\n",
              "stigmabase          676\n",
              "Weeklyvoice         415\n",
              "johnnybebad666_     388\n",
              "                   ... \n",
              "dodger1               1\n",
              "almostanythingi       1\n",
              "melissafreyauth       1\n",
              "joejoetill            1\n",
              "cupcakesally          1\n",
              "Name: user_screen_name, Length: 26396, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qo_vXFAnmCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_news = pd.read_csv(os.path.join(path, 'news_org_summary_2018.csv'), header = 0, sep = ',')                          \n",
        "#print(df_news['country.query'].value_counts())\n",
        "df_news = df_news[df_news['country.query'] == 'USA_en']\n",
        "newscreen_names = list(df_news['user_screen_name'].values)\n",
        "newscreen_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgRpdIDcl8KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "44488fb1-6f0d-49bf-b7c1-e42a307c451b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    240\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svtb2LqAn6-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_geotagged.sort_values(['user_followers_count'], ascending = False)['user_screen_name'].value_counts().to_csv(os.path.join(path, 'ieee_geotagged_user_screen_names.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2dTlieeozCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ba213220-c932-484f-cebc-3dca1571d6b8"
      },
      "source": [
        "df_geotagged[df_geotagged['user_screen_name.1'].isin(newscreen_names)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>coordinates</th>\n",
              "      <th>created_at</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>media</th>\n",
              "      <th>urls</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>id</th>\n",
              "      <th>in_reply_to_screen_name</th>\n",
              "      <th>in_reply_to_status_id</th>\n",
              "      <th>in_reply_to_user_id</th>\n",
              "      <th>lang</th>\n",
              "      <th>place</th>\n",
              "      <th>possibly_sensitive</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reweet_id</th>\n",
              "      <th>retweet_screen_name</th>\n",
              "      <th>source</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_url</th>\n",
              "      <th>user_created_at</th>\n",
              "      <th>user_screen_name</th>\n",
              "      <th>user_default_profile_image</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_favourites_count</th>\n",
              "      <th>user_followers_count</th>\n",
              "      <th>user_friends_count</th>\n",
              "      <th>user_listed_count</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_screen_name.1</th>\n",
              "      <th>user_statuses_count</th>\n",
              "      <th>user_time_zone</th>\n",
              "      <th>user_urls</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [coordinates, created_at, hashtags, media, urls, favorite_count, id, in_reply_to_screen_name, in_reply_to_status_id, in_reply_to_user_id, lang, place, possibly_sensitive, retweet_count, reweet_id, retweet_screen_name, source, text, tweet_url, user_created_at, user_screen_name, user_default_profile_image, user_description, user_favourites_count, user_followers_count, user_friends_count, user_listed_count, user_location, user_name, user_screen_name.1, user_statuses_count, user_time_zone, user_urls, user_verified, is_retweet]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUjeoj6o9TG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "dc4ab9e9-c745-448e-cb46-e912a35b532c"
      },
      "source": [
        "df_geotagged['user_screen_name.1'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VirallyAds         2170\n",
              "pairsonnalitesN    1764\n",
              "stigmabase          676\n",
              "Weeklyvoice         415\n",
              "johnnybebad666_     388\n",
              "                   ... \n",
              "MarkyNDenverxxx       1\n",
              "DrJoyArciaga          1\n",
              "nadiarosemusic        1\n",
              "LiveGreenTO           1\n",
              "capati_patrick        1\n",
              "Name: user_screen_name.1, Length: 26392, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZYdsbk8pbnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "0109686f-7706-46af-c5da-3828eef39fc7"
      },
      "source": [
        "!pip install newsapi-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newsapi-python\n",
            "  Downloading https://files.pythonhosted.org/packages/de/9e/9050199ac7cbc755d1c49577fdaa5517901124b574264b3602a8b8028440/newsapi_python-0.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from newsapi-python) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->newsapi-python) (3.0.4)\n",
            "Installing collected packages: newsapi-python\n",
            "Successfully installed newsapi-python-0.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xLv0IbNr_IF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from newsapi import NewsApiClient\n",
        "\n",
        "# Init\n",
        "newsapi = NewsApiClient(api_key=\"key\")\n",
        "\n",
        "# /v2/top-headlines\n",
        "# top_headlines = newsapi.get_top_headlines(q='bitcoin',\n",
        "#                                           sources='bbc-news,the-verge',\n",
        "#                                           category='business',\n",
        "#                                           language='en',\n",
        "#                                           country='us')\n",
        "# print(top_headlines)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjstBsk8sPh5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "4715a893-7bbc-4555-a4dc-4a7d3d48fdb6"
      },
      "source": [
        "# /v2/sources\n",
        "sources = newsapi.get_sources(country= 'us')\n",
        "print(len(sources))\n",
        "df_news_api = pd.DataFrame(sources['sources'])\n",
        "df_news_api.to_csv(os.path.join(path, 'news_api_names.csv'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NewsAPIException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNewsAPIException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7f12a0442c9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# /v2/sources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewsapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'us'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_news_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_news_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news_api_names.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/newsapi/newsapi_client.py\u001b[0m in \u001b[0;36mget_sources\u001b[0;34m(self, category, language, country)\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;31m# Check Status of Request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mNewsAPIException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNewsAPIException\u001b[0m: {'status': 'error', 'code': 'rateLimited', 'message': 'You have made too many requests recently. Developer accounts are limited to 500 requests over a 24 hour period (250 requests available every 12 hours). Please upgrade to a paid plan if you need more requests.'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbUyx25NyM_r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "07ee0ba2-5de0-4c88-9e38-179ddbdb29de"
      },
      "source": [
        "set(df_news_api['name'].values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-be34c882a865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_news_api\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_news_api' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqRcW6tJsVok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "f6253e45-a3a9-4ffd-f990-be22085760fd"
      },
      "source": [
        "# /v2/everything\n",
        "all_articles = newsapi.get_everything(q='covid',\n",
        "                                      \n",
        "                                      from_param='2020-06-24',\n",
        "                                      to='2020-07-10',\n",
        "                                      language='en',\n",
        "                                      sort_by='relevancy',\n",
        "                                      page=2)\n",
        "pd.DataFrame(all_articles['articles'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dcc8a34c30ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# /v2/everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m all_articles = newsapi.get_everything(q='coronavirus',\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                       \u001b[0mfrom_param\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2020-06-24'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                       \u001b[0mto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2020-07-10'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'newsapi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmWMn4gFygce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzoD5_OetPvH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "44bd962c-d865-4fdf-d246-4e55eed24f5a"
      },
      "source": [
        "df_all_ids = pd.read_csv(os.path.join(path, 'all_no_geotagged_tweet_ids.csv'), header = None)\n",
        "df_all_ids.columns = ['id', 'some_measure']\n",
        "df_geotagged.drop_duplicates(inplace=True)\n",
        "df_all_ids = df_all_ids[['id']]\n",
        "df_all_ids.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1279619193709658112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1279619193839607811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1279619193915113476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1279619194183733251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1279619194573606915</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id\n",
              "0  1279619193709658112\n",
              "1  1279619193839607811\n",
              "2  1279619193915113476\n",
              "3  1279619194183733251\n",
              "4  1279619194573606915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uFTkwFOv8U1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_all_ids.to_csv(os.path.join(path, 'all_tweets_ieee.csv'), header= None, index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuzqBLl-PA1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dae2be88-47fd-464b-e028-a5f0a2cf9d87"
      },
      "source": [
        "i =0\n",
        "with open(os.path.join(path, 'all_tweets_ieee.csv')) as f:\n",
        "  for line in f.readlines():\n",
        "    if i <5:\n",
        "      print(line)\n",
        "      i +=1 \n",
        "    else:\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1279619193709658112\n",
            "\n",
            "1279619193839607811\n",
            "\n",
            "1279619193915113476\n",
            "\n",
            "1279619194183733251\n",
            "\n",
            "1279619194573606915\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgQw_blTw4i1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e630b040-22fe-4e9b-8e62-9a5c3385af8d"
      },
      "source": [
        "len(df_all_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51288288"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlLQ3dLNpOZ",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q4MXk4AxbR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utility function for data preprocessing (METHOD 1)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten','may','also','across','among','beside','however','yet','within'])\n",
        "re_stop_words = re.compile(r\"\\b(\" + \"|\".join(stop_words) + \")\\\\W\", re.I)\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def cleanHtml(sentence):\n",
        "    cleanr = re.compile(r\"http\\S+\")\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "def keepAlpha(sentence):\n",
        "    alpha_sent = \"\"\n",
        "    for word in sentence.split():\n",
        "        alpha_word = re.sub('[^a-z A-Z]+', ' ', word)\n",
        "        alpha_sent += alpha_word\n",
        "        alpha_sent += \" \"\n",
        "    alpha_sent = alpha_sent.strip()\n",
        "    return alpha_sent\n",
        "def removeStopWords(sentence):\n",
        "    global re_stop_words\n",
        "    return re_stop_words.sub(\" \", sentence)\n",
        "\n",
        "def stemming(sentence):\n",
        "    stemSentence = \"\"\n",
        "    for word in sentence.split():\n",
        "        stem = stemmer.stem(word)\n",
        "        stemSentence += stem\n",
        "        stemSentence += \" \"\n",
        "    stemSentence = stemSentence.strip()\n",
        "    return stemSentence\n",
        "def replace_mentioned(tweet):\n",
        "        '''This function will extract the twitter handles of people mentioned in the tweet'''\n",
        "        return re.sub('(?<!RT\\s)(@[A-Za-z]+[A-Za-z0-9-_]+)',\"\", tweet)\n",
        "    \n",
        "def find_hashtags(sentence):\n",
        "        '''This function will extract hashtags'''\n",
        "        return re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', \"\", sentence)\n",
        "def fix_abbreviation(text):\n",
        "    text = re.sub(r'\\b(?:vs|VS|Vs)\\b\\.*', 'versus', text)\n",
        "    text = re.sub(r\"'ve\\b\", ' have', text)\n",
        "    # text = re.sub(r\"\\b(btw|BTW)\\b\", 'by the way', text)\n",
        "    # text = re.sub(r\"\\b(asap|ASAP)\\b\", 'as soon as possible', text)\n",
        "    # text = re.sub(r\"\\b(af|AF)\\b\", 'as fuck', text)\n",
        "    # text = re.sub(r\"\\b(AFAIK)\\b\", 'as far as I know', text)\n",
        "    text = re.sub(r\"\\b(DM)\\b\", 'direct message', text)\n",
        "    text = re.sub(r\"\\b(EM)\\b\", 'email', text)\n",
        "    text = re.sub(r\"\\b(FB)\\b\", 'facebook', text)\n",
        "    # text = re.sub(r\"\\b(OMG)\\b\", 'oh my god', text)\n",
        "    return text\n",
        "\n",
        "def remove_extras(text):\n",
        "    # Remove 'RT'\n",
        "    text = re.sub(r'RT\\b', '', text)\n",
        "    # Remove user's handle and email addres\n",
        "    text = re.sub(r'\\S*@\\S*\\s?', '', text)\n",
        "    # Remove links\n",
        "    text = re.sub(r'http(s)?\\:\\/\\/t\\.co\\/\\w*', '', text)\n",
        "    # Remove digits and words that has digit(s) except those network related\n",
        "    # text = re.sub(r'(?!5g|5G|4g|4G|3g|3G|2g|2G)\\w*\\d+\\w*', '', text)\n",
        "    text = re.sub(r'\\W\\b(\\d+)\\b', '', text)\n",
        "    # Remove '-'\n",
        "    text = re.sub(r'-', '', text)\n",
        "    # Remove distracting double quotes\n",
        "    text = re.sub(r\"\\”\", '\\\"', text)\n",
        "    text = re.sub(r\"\\“\", '\\\"', text)\n",
        "    text = re.sub(r\"\\\"\", '', text)\n",
        "    # Remove distracting single quotes\n",
        "    text = re.sub(r\"\\’\", '\\'', text)\n",
        "    text = re.sub(r\"\\‘\", '\\'', text)\n",
        "    text = re.sub(r\"\\'s\", '', text)\n",
        "    # text = re.sub(r\"\\'ve\", ' have', text)\n",
        "    text = re.sub(r\"\\'\", '', text)\n",
        "    # Remove extra whitespaces\n",
        "    text = ' '.join([word for word in text.split()])\n",
        "\n",
        "    return text\n",
        "def reduce_lengthening(text):\n",
        "    \"\"\"\n",
        "    Fixing Word Lengthening ~ finalllly -> finally\n",
        "    \"\"\"\n",
        "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
        "    return pattern.sub(r\"\\1\\1\", text)\n",
        "def clean_ascii(text):\n",
        "    # function to remove non-ASCII chars from data\n",
        "    return ''.join(i for i in text if ord(i) < 128)\n",
        "\n",
        "def clean_HT_MT_Html(text):\n",
        "  text = replace_mentioned(text)\n",
        "  #text = find_hashtags(text)\n",
        "  text = cleanHtml(text)\n",
        "  text = clean_ascii(text)\n",
        "  # Remove punctuations\n",
        "  punc_free = ''.join([ch for ch in text if ch not in string.punctuation])\n",
        "\n",
        "  # Fix misspelled words\n",
        "  text = ' '.join([spell.correction(word) for word in punc_free.split()])\n",
        "  text = text.strip()\n",
        "  return text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQmuyTgjOGQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Utility function for data preprocessing (METHOD 2)\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['zero','is','lol','yr','fu', 'weeks','im', 'u','one', 'day', 'week', 'two', 'dont', 'it', 'isnt',\"isn't\", \"don't\",'not','yes','no','next'])\n",
        "puncs = string.punctuation\n",
        "lemma = WordNetLemmatizer()\n",
        "spell = SpellChecker(distance=1)\n",
        "# Add unknown words to spell checker\n",
        "spell.word_frequency.load_words(['Covid', 'covid', 'COVID', 'corona'])\n",
        "\n",
        "def clean_doc(text):\n",
        "    # pdb.set_trace()\n",
        "\n",
        "    # Fix some common abbreviations\n",
        "    text = fix_abbreviation(text)\n",
        "    text = cleanHtml(text)\n",
        "    text = replace_mentioned(text)\n",
        "    #text = find_hashtags(text)\n",
        "\n",
        "    # Remove unnecessary tokens like username, email and '-'\n",
        "    text = remove_extras(text)\n",
        "    # Remove extra repeated characters\n",
        "\n",
        "    text = reduce_lengthening(text)\n",
        "    \n",
        "    text = keepAlpha(text)\n",
        "    # Remove punctuations\n",
        "    punc_free = ''.join([ch for ch in text if ch not in puncs])\n",
        "\n",
        "    # Fix misspelled words\n",
        "    spell_corrected = ' '.join([spell.correction(word) for word in punc_free.split()])\n",
        "\n",
        "    # Lemmatize word using WordNetLemmatizer\n",
        "    # Define word's role (POS) for better lemmatization result\n",
        "    lemmaztized_words = []\n",
        "    for word, pos in nltk.pos_tag(spell_corrected.split()):\n",
        "        if pos[:2] == 'VB':     # if verb\n",
        "            tag = 'v'\n",
        "        elif pos[:2] == 'JJ':   # if adjective\n",
        "            tag = 'a'\n",
        "        else:\n",
        "            tag = 'n'\n",
        "        lemmaztized_words.append(lemma.lemmatize(word, pos=tag))\n",
        "    normalized = ' '.join([word for word in lemmaztized_words])\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_free = ' '.join([word for word in normalized.lower().split() if word not in stop_words])\n",
        "\n",
        "    return stop_free"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ4nT39zOKfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df_geotagged\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAAL-qtDOPFu",
        "colab_type": "text"
      },
      "source": [
        "#### Cleaning Method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3lIvM6PON1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text_clean'] = df.text.apply(lambda x: clean_doc(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VCJ7CEiOR6I",
        "colab_type": "text"
      },
      "source": [
        "#### Cleaning Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKIshFiWOUje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['text_noHT_MT'] = df.text.apply(lambda x: clean_HT_MT_Html(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjCalc7KOT55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint\n",
        "pprint(df[['text', 'text_noHT_MT']].head(1)['text'][0])\n",
        "pprint(df[['text', 'text_noHT_MT']].head(1)['text_noHT_MT'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbBcSa-COhMU",
        "colab_type": "text"
      },
      "source": [
        "### Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrNPqEPmOikr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize afinn sentiment analyzer\n",
        "\n",
        "from afinn import Afinn\n",
        "af = Afinn()\n",
        "\n",
        "# compute sentiment scores (polarity) and labels\n",
        "sentiment_scores = [af.score(tweet) for tweet in df['text_clean'].values]\n",
        "sentiment_category = ['positive' if score > 0 \n",
        "                          else 'negative' if score < 0 \n",
        "                              else 'neutral' \n",
        "                                  for score in sentiment_scores]\n",
        "df['sentiment_score'] = sentiment_scores\n",
        "df['sentiment_category']  = sentiment_category\n",
        "print(df.columns)    \n",
        "# sentiment statistics per news category\n",
        "df_senti = pd.DataFrame([list(df['text']), list(df['text_clean']), sentiment_scores, sentiment_category]).T\n",
        "df_senti.columns = ['tweet', 'cleaned_text', 'sentiment_score', 'sentiment_category']\n",
        "df_senti['sentiment_score'] = df_senti.sentiment_score.astype('float')\n",
        "df_senti.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}